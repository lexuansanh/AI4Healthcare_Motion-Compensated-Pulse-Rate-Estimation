{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Algorithm\n",
    "\n",
    "## Instructions\n",
    "1. From the **Pulse Rate Algorithm** Notebook you can do one of the following:\n",
    "   - Copy over all the **Code** section to the following Code block.\n",
    "   - Download as a Python (`.py`) and copy the code to the following Code block.\n",
    "2. In the bottom right, click the <span style=\"color:blue\">Test Run</span> button. \n",
    "\n",
    "### Didn't Pass\n",
    "If your code didn't pass the test, go back to the previous Concept or to your local setup and continue iterating on your algorithm and try to bring your training error down before testing again.\n",
    "\n",
    "### Pass\n",
    "If your code passes the test, complete the following! You **must** include a screenshot of your code and the Test being **Passed**. Here is what the starter filler code looks like when the test is run and should be similar. A passed test will include in the notebook a green outline plus a box with **Test passed:** and in the Results bar at the bottom the progress bar will be at 100% plus a checkmark with **All cells passed**.\n",
    "![Example](example.png)\n",
    "\n",
    "1. Take a screenshot of your code passing the test, make sure it is in the format `.png`. If not a `.png` image, you will have to edit the Markdown render the image after Step 3. Here is an example of what the `passed.png` would look like \n",
    "2. Upload the screenshot to the same folder or directory as this jupyter notebook.\n",
    "3. Rename the screenshot to `passed.png` and it should show up below.\n",
    "![Passed](passed.png)\n",
    "4. Download this jupyter notebook as a `.pdf` file. \n",
    "5. Continue to Part 2 of the Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "nrtnppao4pm",
    "udacity_user_query": ""
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estim0tes = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "\n",
    "def BandpassFilter(signal, fs, pass_band=(40/60, 240/60)):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth bandpass filter to the signal.\n",
    "\n",
    "    Args:\n",
    "        signal (array): The input signal to filter.\n",
    "        pass_band (tuple): The lower and upper frequencies for the bandpass filter.\n",
    "        fs (int): The sampling frequency of the signal.\n",
    "\n",
    "    Returns:\n",
    "        array: The bandpass filtered signal.\n",
    "    \"\"\"\n",
    "    b, a = sp.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def FourierTransform(signal, fs):\n",
    "    \"\"\"\n",
    "    Perform a Fourier Transform on the signal.\n",
    "\n",
    "    Args:\n",
    "        signal (array): The input signal to transform.\n",
    "        fs (int): The sampling frequency of the signal.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Frequencies and the corresponding magnitudes of the signal.\n",
    "    \"\"\"\n",
    "    freqs = np.fft.rfftfreq(2 * len(signal), 1 / fs)\n",
    "    fft = np.abs(np.fft.rfft(signal, 2 * len(signal)))\n",
    "    return freqs, fft\n",
    "\n",
    "def CreateFeatures(ppg, accx, accy, accz, fs):\n",
    "    \"\"\"\n",
    "    Create features from PPG and accelerometer data.\n",
    "\n",
    "    Args:\n",
    "        ppg (array): The PPG signal.\n",
    "        accx (array): The x-axis accelerometer signal.\n",
    "        accy (array): The y-axis accelerometer signal.\n",
    "        accz (array): The z-axis accelerometer signal.\n",
    "        fs (int): The sampling frequency.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Two dictionaries containing FFT and peak information for the accelerometer and PPG signals.\n",
    "            acc_info (dict): Contains the FFT data, frequencies, peaks, peak frequencies, and peak values for the accelerometer.\n",
    "            ppg_info (dict): Contains the FFT data, frequencies, peaks, peak frequencies, and peak values for the PPG.\n",
    "    \"\"\"\n",
    "    # Frequency range for filtering (in Hz)\n",
    "    min_freq = 40 / 60\n",
    "    max_freq = 240 / 60\n",
    "    \n",
    "    # Combine accelerometer signals and perform Fourier Transform\n",
    "    acc = np.sqrt(accx**2 + accy**2 + accz**2)\n",
    "    acc_freqs, acc_fft = FourierTransform(acc, fs)\n",
    "    acc_fft[(acc_freqs <= min_freq) | (acc_freqs >= max_freq)] = 0.0\n",
    "    \n",
    "    # Find acc peaks\n",
    "    acc_peaks, acc_peaks_f  = FindPeaks(acc_fft, acc_freqs)\n",
    "    \n",
    "    # max freq for acc\n",
    "    acc_peak_freq = acc_freqs[np.argmax(acc_fft)]\n",
    "    \n",
    "    # Fourier Transform for PPG\n",
    "    ppg_freqs, ppg_fft = FourierTransform(ppg, fs)\n",
    "    ppg_fft[(ppg_freqs <= min_freq) | (ppg_freqs >= max_freq)] = 0.0\n",
    "    \n",
    "    # Find ppg peaks\n",
    "    ppg_heigh = 2000\n",
    "    ppg_peaks, ppg_peaks_f = FindPeaks(ppg_fft, ppg_freqs, ppg_heigh)\n",
    "    \n",
    "    # max freq for ppg\n",
    "    ppg_peak_freq = ppg_freqs[np.argmax(ppg_fft)]\n",
    "    \n",
    "    \n",
    "    acc_info = {\n",
    "        'fft': acc_fft,\n",
    "        'freqs': acc_freqs,\n",
    "        'peaks': acc_peaks,\n",
    "        'peaks_f': acc_peaks_f,\n",
    "        'peak_freq': acc_peak_freq\n",
    "    }\n",
    "\n",
    "    ppg_info = {\n",
    "        'fft': ppg_fft,\n",
    "        'freqs': ppg_freqs,\n",
    "        'peaks': ppg_peaks,\n",
    "        'peaks_f': ppg_peaks_f,\n",
    "        'peak_freq': ppg_peak_freq\n",
    "    }\n",
    "    return acc_info, ppg_info\n",
    "\n",
    "\n",
    "def FindPeaks(fft, freqs, height=None):\n",
    "    \"\"\"\n",
    "    Identify peaks in the FFT magnitude spectrum and their corresponding frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    fft (array): FFT magnitude spectrum.\n",
    "    freqs (array): Frequencies corresponding to the FFT spectrum.\n",
    "    height (float, optional): Minimum height of peaks to be identified. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "    tuple:\n",
    "        fft_peaks (array): Indices of the identified peaks in the FFT spectrum.\n",
    "        fft_peaks_f (array): Frequencies corresponding to the identified peaks.\n",
    "    \"\"\"\n",
    "    # Find peaks in the FFT magnitude spectrum\n",
    "    fft_peaks = sp.signal.find_peaks(fft, height=height)[0]\n",
    "    \n",
    "    # Get the frequencies corresponding to the identified peaks\n",
    "    fft_peaks_f = freqs[fft_peaks]\n",
    "    \n",
    "    return fft_peaks, fft_peaks_f\n",
    "\n",
    "def EstimateHeartRateWithConfidence(ppg, accx, accy, accz, window_length_s, window_shift_s, fs):\n",
    "    \"\"\"\n",
    "    Estimate the heart rate and calculate the confidence of the estimation.\n",
    "\n",
    "    Args:\n",
    "        ppg (array): The PPG signal.\n",
    "        acc (array): The combined accelerometer signal.\n",
    "        window_length_s (int): The length of each analysis window in seconds.\n",
    "        window_shift_s (int): The shift between successive windows in seconds.\n",
    "        fs (int): The sampling frequency.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The estimated heart rate (in bpm) and the confidence of the estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    window_length = window_length_s * fs\n",
    "    window_shift = window_shift_s * fs\n",
    "    \n",
    "    estimated_bpm = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    previous_estimation = 40 / 60\n",
    "    \n",
    "    # Loop through the signal with defined window length and shift\n",
    "    for i in range(0, len(ppg) - window_length, window_shift):\n",
    "        k = 1\n",
    "        ppg_window = ppg[i:i + window_length]\n",
    "        \n",
    "        # Create features from the windowed signals\n",
    "        acc_info, ppg_info = CreateFeatures(ppg_window, accx, accy, accz, fs)\n",
    "        \n",
    "        # Ensure the peak frequency is not influenced by the accelerometer\n",
    "        while np.abs(acc_info['peak_freq'] - ppg_info['peak_freq']) <= 0.2 and k <= 2:\n",
    "            k += 1\n",
    "            ppg_info['peak_freq'] = ppg_info['freqs'][np.argsort(ppg_info['fft'], axis=0)[-k]]\n",
    "            acc_info['peak_freq'] = acc_info['freqs'][np.argsort(acc_info['fft'], axis=0)[-k]]\n",
    "        \n",
    "        estimated_bpm_freq = ppg_info['peak_freq']\n",
    "        previous_estimation = estimated_bpm_freq\n",
    "        \n",
    "        # Append the estimated BPM and the confidence score\n",
    "        estimated_bpm.append(estimated_bpm_freq * 60)\n",
    "        frequency_window_range_hz = 30 / 60\n",
    "        frequency_window = (ppg_info['freqs'] > estimated_bpm_freq - frequency_window_range_hz) & (ppg_info['freqs'] < estimated_bpm_freq + frequency_window_range_hz)\n",
    "        conf = np.sum(ppg_info['fft'][frequency_window]) / np.sum(ppg_info['fft'])\n",
    "        confidence_scores.append(conf)\n",
    "\n",
    "    return estimated_bpm, confidence_scores\n",
    "\n",
    "\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    Run the pulse rate algorithm on the given data file and reference file.\n",
    "\n",
    "    Args:\n",
    "        data_fl (str): Path to the data file containing the signals.\n",
    "        ref_fl (str): Path to the reference file containing the ground truth heart rates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Per-estimate mean absolute error and confidence as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    bpm = sp.io.loadmat(ref_fl)['BPM0']\n",
    "    \n",
    "    fs = 125\n",
    "    \n",
    "    # Bandpass Filter the signals\n",
    "    ppg = BandpassFilter(ppg, fs)\n",
    "    accx = BandpassFilter(accx, fs)\n",
    "    accy = BandpassFilter(accy, fs)\n",
    "    accz = BandpassFilter(accz, fs)\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence\n",
    "    estimated_bpm, confidence_scores = EstimateHeartRateWithConfidence(ppg, accx, accy, accz, 8, 2, fs)\n",
    "\n",
    "    # Calculate the mean absolute error\n",
    "    errors = np.abs(np.diag(np.subtract(bpm, estimated_bpm)))\n",
    "    \n",
    "    return errors, confidence_scores"
   ]
  }
 ],
 "metadata": {
  "grader_mode": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
