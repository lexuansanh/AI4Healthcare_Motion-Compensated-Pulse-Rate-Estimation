{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estim0tes = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "\n",
    "def BandpassFilter(signal, fs, pass_band=(40/60, 240/60)):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth bandpass filter to the signal.\n",
    "\n",
    "    Args:\n",
    "        signal (array): The input signal to filter.\n",
    "        pass_band (tuple): The lower and upper frequencies for the bandpass filter.\n",
    "        fs (int): The sampling frequency of the signal.\n",
    "\n",
    "    Returns:\n",
    "        array: The bandpass filtered signal.\n",
    "    \"\"\"\n",
    "    b, a = sp.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def FourierTransform(signal, fs):\n",
    "    \"\"\"\n",
    "    Perform a Fourier Transform on the signal.\n",
    "\n",
    "    Args:\n",
    "        signal (array): The input signal to transform.\n",
    "        fs (int): The sampling frequency of the signal.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Frequencies and the corresponding magnitudes of the signal.\n",
    "    \"\"\"\n",
    "    freqs = np.fft.rfftfreq(2 * len(signal), 1 / fs)\n",
    "    fft = np.abs(np.fft.rfft(signal, 2 * len(signal)))\n",
    "    return freqs, fft\n",
    "\n",
    "def CreateFeatures(ppg, accx, accy, accz, fs):\n",
    "    \"\"\"\n",
    "    Create features from PPG and accelerometer data.\n",
    "\n",
    "    Args:\n",
    "        ppg (array): The PPG signal.\n",
    "        accx (array): The x-axis accelerometer signal.\n",
    "        accy (array): The y-axis accelerometer signal.\n",
    "        accz (array): The z-axis accelerometer signal.\n",
    "        fs (int): The sampling frequency.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Two dictionaries containing FFT and peak information for the accelerometer and PPG signals.\n",
    "            acc_info (dict): Contains the FFT data, frequencies, peaks, peak frequencies, and peak values for the accelerometer.\n",
    "            ppg_info (dict): Contains the FFT data, frequencies, peaks, peak frequencies, and peak values for the PPG.\n",
    "    \"\"\"\n",
    "    # Frequency range for filtering (in Hz)\n",
    "    min_freq = 40 / 60\n",
    "    max_freq = 240 / 60\n",
    "    \n",
    "    # Combine accelerometer signals and perform Fourier Transform\n",
    "    acc = np.sqrt(accx**2 + accy**2 + accz**2)\n",
    "    acc_freqs, acc_fft = FourierTransform(acc, fs)\n",
    "    acc_fft[(acc_freqs <= min_freq) | (acc_freqs >= max_freq)] = 0.0\n",
    "    \n",
    "    # Find acc peaks\n",
    "    acc_peaks, acc_peaks_f  = FindPeaks(acc_fft, acc_freqs)\n",
    "    \n",
    "    # max freq for acc\n",
    "    acc_peak_freq = acc_freqs[np.argmax(acc_fft)]\n",
    "    \n",
    "    # Fourier Transform for PPG\n",
    "    ppg_freqs, ppg_fft = FourierTransform(ppg, fs)\n",
    "    ppg_fft[(ppg_freqs <= min_freq) | (ppg_freqs >= max_freq)] = 0.0\n",
    "    \n",
    "    # Find ppg peaks\n",
    "    ppg_heigh = 2000\n",
    "    ppg_peaks, ppg_peaks_f = FindPeaks(ppg_fft, ppg_freqs, ppg_heigh)\n",
    "    \n",
    "    # max freq for ppg\n",
    "    ppg_peak_freq = ppg_freqs[np.argmax(ppg_fft)]\n",
    "    \n",
    "    \n",
    "    acc_info = {\n",
    "        'fft': acc_fft,\n",
    "        'freqs': acc_freqs,\n",
    "        'peaks': acc_peaks,\n",
    "        'peaks_f': acc_peaks_f,\n",
    "        'peak_freq': acc_peak_freq\n",
    "    }\n",
    "\n",
    "    ppg_info = {\n",
    "        'fft': ppg_fft,\n",
    "        'freqs': ppg_freqs,\n",
    "        'peaks': ppg_peaks,\n",
    "        'peaks_f': ppg_peaks_f,\n",
    "        'peak_freq': ppg_peak_freq\n",
    "    }\n",
    "    return acc_info, ppg_info\n",
    "\n",
    "\n",
    "def FindPeaks(fft, freqs, height=None):\n",
    "    \"\"\"\n",
    "    Identify peaks in the FFT magnitude spectrum and their corresponding frequencies.\n",
    "    \n",
    "    Parameters:\n",
    "    fft (array): FFT magnitude spectrum.\n",
    "    freqs (array): Frequencies corresponding to the FFT spectrum.\n",
    "    height (float, optional): Minimum height of peaks to be identified. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "    tuple:\n",
    "        fft_peaks (array): Indices of the identified peaks in the FFT spectrum.\n",
    "        fft_peaks_f (array): Frequencies corresponding to the identified peaks.\n",
    "    \"\"\"\n",
    "    # Find peaks in the FFT magnitude spectrum\n",
    "    fft_peaks = sp.signal.find_peaks(fft, height=height)[0]\n",
    "    \n",
    "    # Get the frequencies corresponding to the identified peaks\n",
    "    fft_peaks_f = freqs[fft_peaks]\n",
    "    \n",
    "    return fft_peaks, fft_peaks_f\n",
    "\n",
    "def EstimateHeartRateWithConfidence(ppg, accx, accy, accz, window_length_s, window_shift_s, fs):\n",
    "    \"\"\"\n",
    "    Estimate the heart rate and calculate the confidence of the estimation.\n",
    "\n",
    "    Args:\n",
    "        ppg (array): The PPG signal.\n",
    "        acc (array): The combined accelerometer signal.\n",
    "        window_length_s (int): The length of each analysis window in seconds.\n",
    "        window_shift_s (int): The shift between successive windows in seconds.\n",
    "        fs (int): The sampling frequency.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The estimated heart rate (in bpm) and the confidence of the estimation.\n",
    "    \"\"\"\n",
    "\n",
    "    window_length = window_length_s * fs\n",
    "    window_shift = window_shift_s * fs\n",
    "    \n",
    "    estimated_bpm = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    previous_estimation = 40 / 60\n",
    "    \n",
    "    # Loop through the signal with defined window length and shift\n",
    "    for i in range(0, len(ppg) - window_length, window_shift):\n",
    "        k = 1\n",
    "        ppg_window = ppg[i:i + window_length]\n",
    "        \n",
    "        # Create features from the windowed signals\n",
    "        acc_info, ppg_info = CreateFeatures(ppg_window, accx, accy, accz, fs)\n",
    "        \n",
    "        # Ensure the peak frequency is not influenced by the accelerometer\n",
    "        while np.abs(acc_info['peak_freq'] - ppg_info['peak_freq']) <= 0.2 and k <= 2:\n",
    "            k += 1\n",
    "            ppg_info['peak_freq'] = ppg_info['freqs'][np.argsort(ppg_info['fft'], axis=0)[-k]]\n",
    "            acc_info['peak_freq'] = acc_info['freqs'][np.argsort(acc_info['fft'], axis=0)[-k]]\n",
    "        \n",
    "        estimated_bpm_freq = ppg_info['peak_freq']\n",
    "        previous_estimation = estimated_bpm_freq\n",
    "        \n",
    "        # Append the estimated BPM and the confidence score\n",
    "        estimated_bpm.append(estimated_bpm_freq * 60)\n",
    "        frequency_window_range_hz = 30 / 60\n",
    "        frequency_window = (ppg_info['freqs'] > estimated_bpm_freq - frequency_window_range_hz) & (ppg_info['freqs'] < estimated_bpm_freq + frequency_window_range_hz)\n",
    "        conf = np.sum(ppg_info['fft'][frequency_window]) / np.sum(ppg_info['fft'])\n",
    "        confidence_scores.append(conf)\n",
    "\n",
    "    return estimated_bpm, confidence_scores\n",
    "\n",
    "\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    Run the pulse rate algorithm on the given data file and reference file.\n",
    "\n",
    "    Args:\n",
    "        data_fl (str): Path to the data file containing the signals.\n",
    "        ref_fl (str): Path to the reference file containing the ground truth heart rates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Per-estimate mean absolute error and confidence as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    bpm = sp.io.loadmat(ref_fl)['BPM0']\n",
    "    \n",
    "    fs = 125\n",
    "    \n",
    "    # Bandpass Filter the signals\n",
    "    ppg = BandpassFilter(ppg, fs)\n",
    "    accx = BandpassFilter(accx, fs)\n",
    "    accy = BandpassFilter(accy, fs)\n",
    "    accz = BandpassFilter(accz, fs)\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence\n",
    "    estimated_bpm, confidence_scores = EstimateHeartRateWithConfidence(ppg, accx, accy, accz, 8, 2, fs)\n",
    "\n",
    "    # Calculate the mean absolute error\n",
    "    errors = np.abs(np.diag(np.subtract(bpm, estimated_bpm)))\n",
    "    \n",
    "    return errors, confidence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Description\n",
    "\n",
    "### How to Run the Code\n",
    "\n",
    "To run the code and use the algorithm:\n",
    "\n",
    "1. **Dataset Preparation**: Ensure the Troika dataset is correctly downloaded and stored in the specified directory (`./datasets/troika/training_data`). This dataset consists of pairs of `.mat` files: `DATA_*.mat` containing signal data and `REF_*.mat` containing reference heart rates.\n",
    "\n",
    "2. **Functions Provided**:\n",
    "   - `LoadTroikaDataset()`: Retrieves the filenames of the dataset files.\n",
    "   - `LoadTroikaDataFile(data_fl)`: Loads and extracts signals (PPG, accelerometer data) from a specific Troika `.mat` file.\n",
    "   - `RunPulseRateAlgorithm(data_fl, ref_fl)`: Runs the pulse rate estimation algorithm on a given data file and corresponding reference file.\n",
    "   - Various signal processing functions (`BandpassFilter`, `FourierTransform`, `CreateFeatures`, etc.) used within the algorithm.\n",
    "\n",
    "3. **Execution**: \n",
    "   - Import necessary libraries (`numpy`, `scipy`).\n",
    "   - Ensure all functions (`RunPulseRateAlgorithm`, signal processing functions) are accessible.\n",
    "   - Call `Evaluate()` function to compute aggregate error metrics over the entire Troika dataset.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "### Dataset Used\n",
    "\n",
    "The Troika dataset used consists of PPG signals along with accelerometer data from wrist-worn devices. These signals are collected during various activities to estimate heart rates. Each `.mat` file pair (`DATA_*.mat` and `REF_*.mat`) provides:\n",
    "- PPG signal (photoplethysmogram).\n",
    "- Three-axis accelerometer signals (x, y, z).\n",
    "- Reference heart rate (BPM0) derived from independent measurements.\n",
    "\n",
    "### Shortcomings\n",
    "\n",
    "**Shortcomings**:\n",
    "- Lack of detailed contextual information (e.g., activity type, subject's health status).\n",
    "- Limited diversity in demographic factors such as age, fitness level, and health conditions.\n",
    "\n",
    "### Improvements\n",
    "\n",
    "**Improvements**:\n",
    "- To build a more complete dataset, additional data capturing diverse activities, demographics, and health conditions would be beneficial. This would enhance algorithm robustness and generalizability.\n",
    "\n",
    "## Algorithm Description\n",
    "\n",
    "### How the Algorithm Works\n",
    "\n",
    "**How the Algorithm Works**:\n",
    "1. **Data Preprocessing**: Signals are bandpass filtered to focus on frequency components relevant for heart rate estimation.\n",
    "2. **Feature Extraction**: Features are extracted using Fourier Transform to identify dominant frequency peaks in both PPG and accelerometer signals.\n",
    "3. **Heart Rate Estimation**: \n",
    "   - By analyzing the peak frequencies and their magnitudes, the algorithm estimates the heart rate.\n",
    "   - Confidence in each estimation is computed based on the relative magnitude of the dominant peaks.\n",
    "\n",
    "### Specific Aspects of Physiology\n",
    "\n",
    "**Physiological Aspects Taken Advantage of**:\n",
    "- PPG signals reflect changes in blood volume in the wrist, synchronized with heartbeats.\n",
    "- Accelerometer signals provide motion context, aiding in distinguishing true heart rate-related pulsations from motion artifacts.\n",
    "\n",
    "### Algorithm Outputs\n",
    "\n",
    "**Algorithm Outputs**:\n",
    "- Estimated heart rate (in beats per minute, BPM) for each analysis window.\n",
    "- Confidence score indicating the reliability of each heart rate estimate.\n",
    "\n",
    "### Caveats on Algorithm Outputs\n",
    "\n",
    "**Caveats on Algorithm Outputs**:\n",
    "- Motion artifacts or irregular physiological responses may affect estimation accuracy.\n",
    "- Confidence scores are relative and may vary based on signal quality and activity type.\n",
    "\n",
    "### Common Failure Modes\n",
    "\n",
    "**Common Failure Modes**:\n",
    "- Insufficient motion filtering leading to inaccurate peak identification.\n",
    "- Inaccurate heart rate estimates due to weak PPG signals or excessive noise.\n",
    "\n",
    "## Algorithm Performance\n",
    "\n",
    "### Performance Evaluation\n",
    "\n",
    "**Performance Evaluation**:\n",
    "- **Error Metric**: Mean Absolute Error (MAE) at 90% availability (i.e., considering the best estimates with higher confidence).\n",
    "- **Cross-Validation**: The algorithm evaluates performance across different activities and subjects within the Troika dataset.\n",
    "- **Metrics Optimized For**: Optimized to minimize MAE, particularly focusing on accurate heart rate estimation during various activities and conditions.\n",
    "\n",
    "### Generalizability\n",
    "\n",
    "**Generalizability**:\n",
    "- Performance metrics are specific to the Troika dataset and may vary on different datasets due to varying signal quality and characteristics.\n",
    "- Acknowledgment of limitations in generalizing results to broader populations or activities not represented in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
